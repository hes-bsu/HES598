---
title: "Introduction to parallelization"
author: "Matt Williamson"
date: "3/2/2020"
output: 
    ioslides_presentation:
        css: style.css
        theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(googledrive)
library(raster)
library(tidyverse)
```

## Today's objectives

- Introduce the `apply` and `map_` family of functions for repeated operations

- Describe parallel computing and introduce `embarassingly parallel` computation

- Introduce `mclapply` and `future_map` for local parallelization

## The `apply` function

- `apply` requires three arguments: an `array`, the `margin`, and the `function` you want to execute

- `arrays`are R data objects that contain 1, 2, or more dimensions

- `margins` identify which parts of the array to apply the `function` over (1 = rows, 2 = columns, 1:2 = all cells in a matrix) 

## An example with `apply`

```{r applyintro}
#create data
test.matrix <- matrix(rnorm(200), 20, 10)
dim(test.matrix)
# generate column means
apply(X=test.matrix, MARGIN = 2, mean)
#generate row sums
apply(X=test.matrix, MARGIN = 1, sum)
#exponentiate each cell of the data
apply(X=test.matrix, MARGIN = 1:2, exp)

```


## The `apply` family

- A flexible group of functions that replace `for` or `while` loops

- Translates loops in C++ code, often provides speed-up

- Which member of the 'family' depends on input data and output desired

- Can be tricky to get desired behavior (*algorithmic efficiency* vs. *programmer efficiency*)


## Using `lapply` for spatial data

```{r lapplyintro}
#get filenames from Google Drive

folder_url <- "https://drive.google.com/open?id=1xSsKYpB2o9SEIo6pZDFWYqVthb162_Zo"
folder <- drive_get(as_id(folder_url))
tif_files <- drive_ls(folder)
lapply(tif_files$id, function(x) drive_download(as_id(x), overwrite = TRUE))

rstr.names <- list.files(pattern = "*.tif")
rstrs <- lapply(rstr.names, raster)
plot(rstrs[[1]])
```

## Mosaicing a list of rasters

```{r mosintro}

names(rstrs)[1:2] <- c('x', 'y')
rstrs$fun <- mean
rstrs$na.rm <- TRUE
mos <- do.call(mosaic, rstrs)
plot(mos)
```

## The `map` function from `purrr` and the `tidyverse` 

- Acts like `apply` but can be more flexible and interpretable
- Has a similar 'family' of functions designed for different situations

```{r}
folder_url <- "https://drive.google.com/open?id=1xSsKYpB2o9SEIo6pZDFWYqVthb162_Zo"
folder <- drive_get(as_id(folder_url))
tif_files <- drive_ls(folder)
map(tif_files$id, ~drive_download(as_id(.x), overwrite = TRUE))
```

## Parallelism and spatial computing

- `lapply` and `map` work serially

- Parallelization is useful when pieces of a problem are independent 

- "Embarassingly parallel" refers to problems that can be broken down into small chunks and run simultaneously using your computer's different processors

- `mclapply` and `future_map` allow this in a general way; `raster` allows some implicit parallelism

```{r}
library(parallel)
detectCores()

```

## Using `mclapply` to extract data

- relies on "forking" 

- Can be slower than standard processing if the dataset being copied to the child process is large

```{r mcltest}
counties.id <- tigris::counties("id")
counties.p <- spTransform(counties.id, proj4string(mos))

counties.ext <- mclapply(seq_along(counties.p), function(x){
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
}, mc.cores = 4)
```

## Evaluating `mclapply` to extract data

```{r timing}
s.mclapply <- system.time(mclapply(seq_along(counties.p), function(x){
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
}, mc.cores = 4))

s.lapply <- system.time(lapply(seq_along(counties.p), function(x){
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
}))
s.mclapply
s.lapply
```
## Translating to the `map_` family
- relies on the `furrr` package
```{r futureexp}
library(furrr)
future::plan(multiprocess)

counties.ext <- future_map(seq_along(counties.p), function(x){
  library(sf) #each operation in a new session
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
})

```

## Timing `future_`

```{r}
s.future <- system.time(future_map(seq_along(counties.p), function(x){
  library(sf) #each operation in a new session
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
}))

s.map <- system.time(map(seq_along(counties.p), function(x){
  library(sf) #each operation in a new session
  cty.sf = as(counties.p, "sf") 
  cty.ext = cty.sf[x,] %>% as(., "Spatial")
  raster::extract(mos, cty.ext)
}))
s.future
s.map
```


## Additional directions

- socket clusters (`makeCluster`, `parLapply`) - Useful when data needs to be passed back and forth among jobs (see [R Programming for Data Science](https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html))

- lots of variations on `map_` (see the [purrr documentation](https://purrr.tidyverse.org/reference/map.html)) and `apply`

- The `foreach` package adds additional functionalilty (see [this blog](https://www.r-bloggers.com/how-to-go-parallel-in-r-basics-tips/) for more info on parallel processing)




