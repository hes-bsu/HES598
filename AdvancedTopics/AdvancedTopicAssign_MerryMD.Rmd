---
title: "Advanced Topic: Landscape Metrics and Raster Data"
author: "Merry Davidson"
date: "4/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rgdal)
library(raster)
```


SAVE YOUR FILE IN THE AdvancedTopics FOLDER IN THE GIT REPO

## Introduction:
My thesis research aims to quantify the degree of landscape change on the landscape. The study site of interest is the Rupununi savanna-forest boundary located on the Southwest portion of Guyana (South America). In order to quantify change, I have generated rasters using Spectral Unmixing Analysis (SUA) classification for the period of 2000-2018.
My chosen Advanced Topic for this course is: Landscape Metrics and Raster Data. 
My goal for this assignment is to learn how to use raster data in R by using raster packages and fucntions [Specify wich ones here}}}. Specifically, I will obtain SUA pixel totals of 13 specific points in a subset of my study area.  
Bigger picture: This inforation will be used in a statistical generalized linear model that will look at wildlife-landscape interactions.



## PSUEDOCODE:


```{r}
#load the libraries - tell us which packages you're using and why
##Both raster packages to help format my 2 rasters  
## library(rgdal)
## library(raster)


#load your data - which datasets do you need?
##Dadanawa raster file Landsat 7, year 2015 greenest pixel composite image "DADYR15"
#DADYR15 <- raster()
##The SUA classification of year 2015 "SUADAD15"
#SUADAD15 <- raster()
##GPS points to get SUA totals for "DADPTS"
#DADPTS <- read.csv()


#Organize the data - what form should the data be in? A list? how many elements, a data frame? how many rows and columns?
##Make sure the two rasters stack up

#Analysis/processing step 1 - what are you hoping to do here, why? 
#Quantify the metrics by landcover type: water, forest, bareground and quantify the amount of patches per class

#Analysis/processing step 2 - what are you hoping to do here, why? 
#Are there differences in SUA values between the points? 9 out of the 13 points have been classified as bush island habitats. Is there more resolution or variability using SUA values instead of the catergorical habitat description?

#Check the outcomes? How will you know if your steps worked?
#If I have a SUA value for 13 points I will know I did it correctly.

#
```

## Introduce the packages
Given your psuedo code, where is the critical step? What packages and functions are you considering to help you complete this step? Why did you choose them? 
#library(googledrive) where data is stored
#for loading in the data
## library(rgdal)
## library(raster)to load rasters

#Actual code:
Load data

```{r}
#for loading in the data
## ########
#library(googledrive) #where data is stored
# designate project-specific cache
#options(gargle_oauth_cache = ".merrymd")
# check the value of the option, if you like
#gargle::gargle_oauth_cache()
# trigger auth on purpose --> store a token in the specified cache
#drive_auth()
###Run the above one time,done####

library(googledrive)
#authenticating google drive
options(
  gargle_oauth_cache = ".merrymd",
  gargle_oauth_email = TRUE
)


library(curl) #called for Google Drive data access
library(here) #called for Google Drive data access (be srue to make a temp folder for downloads)


folder_url <- "https://drive.google.com/open?id=1Co7q8ggqr1CjbdUcbN0-9LtnHygshKkq"

folder <- drive_get(as_id(folder_url))

files <- drive_ls(folder)

lapply(files$id, function(x) drive_download(as_id(x), path = paste0(here::here("datatemp/original/"), files[files$id==x,]$name), overwrite = TRUE))



##delete below later
#load in  Year 2015 raster
#SUADAD15 <- raster("C:/Users/Nessa/Courses/HES598/datatemp/originalYear2015.tif")
#visualize the rasters
#plot(DADYR15)

```

#GPS Points
```{r}
#load in points (UTM transformed points in a shapefile)
DADPTS <- readOGR("C:/Users/Nessa/Courses/HES598/datatemp/originalUTMzone21N.shp")
str(DADPTS)#check the data
plot(DADPTS)
```

#SUA Year 2015 raster 

```{r}
library(rgdal)
library("raster") #to load rasters
#load in SUA Year 2015 raster
SUADAD15 <- raster("C:/Users/Nessa/Courses/HES598/datatemp/originalYear2015_UTMzone21N.tif")
plot(SUADAD15)
```


#Make 100m buffers around the points

```{r}
library("rgdal")
library("rgeos")
library("sp")
library("raster")

library("rgeos")#for the buffer function, gBuffer(); ###rgdal workded also..
buffDADPTS <- gBuffer(DADPTS,byid=T,width=100) #width is in meter
plot(buffDADPTS)#visually check
```

#Combine Geometry Points with SUA raster data
```{r}
#transform raster into UTMs to match the point data
library(raster)
#first, check your projections
proj4string(SUADAD15)  "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

proj4string(buffDADPTS) "+proj=utm +zone=21 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
#second, transform
library(sp)
library(rgdal)
utmSUADAD15 <- spTransform(SUADAD15, CRS(projargs = "+proj=utm +zone=21 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))



mskbuffDADPTS <- mask(x=SUADAD15,mask=buffDADPTS)#mask function to reduce the raster to buffer object
plot(mskbuffDADPTS)

```


## Evaluate your choices
Use profiling and benchmarking to evaluate which of your options is likely to be the fastest. How does the syntax and/or ease of use of that function impact your decision of whether or not to use it? (For example, velox is much faster than raster, but it's less well documented and the syntax is strange to get used to).

## Show us your final product
Did you make a map? Let's see it. Did you plot some data that you extracted with raster? show us that plot. Did you have an idea of how the data should look after you were done processing it? Were you successful? What went wrong

## Reflect
Write a few sentences on what you learned from this exercise. How has your skill improved? What do you wish you understood better? What do you imagine your next steps to be?

Once you're done push the "knit" button to create the html page from your Rmarkdown document. If you've got questions, let me know!!